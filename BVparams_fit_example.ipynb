{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chunhuili/opt/anaconda3/envs/mp/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/Users/chunhuili/opt/anaconda3/envs/mp/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    }
   ],
   "source": [
    "from bond_valence_processor import BondValenceProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cations = ['B'] # a list of cation species\n",
    "my_api_key = \"YgzOEXsODWlsR0J9P5aSjX2CxHuZX9Zv\"\n",
    "algos = ['shgo', 'brute', 'diff', 'dual_annealing', 'direct']\n",
    "processor = BondValenceProcessor(my_api_key, algos)\n",
    "    \n",
    "for cation in cations:\n",
    "    processor.process_cation_system(cation)\n",
    "\n",
    "# Correct SSH format for GitHub is:\n",
    "# git@github.com:username/repo.git\n",
    "# So for your case it should be:\n",
    "# git@github.com:nodameCL/BondValenceParametersFit.git\n",
    "\n",
    "# First check if you have SSH access set up properly:\n",
    "# 1. Generate SSH key if you haven't:\n",
    "# ssh-keygen -t ed25519 -C \"your_email@example.com\"\n",
    "# (press enter to accept default location)\n",
    "\n",
    "# 2. Add SSH key to ssh-agent:\n",
    "# eval \"$(ssh-agent -s)\"\n",
    "# ssh-add ~/.ssh/id_ed25519\n",
    "\n",
    "# 3. Copy public key to clipboard:\n",
    "# pbcopy < ~/.ssh/id_ed25519.pub\n",
    "\n",
    "# 4. Add SSH key to GitHub account:\n",
    "# - Go to GitHub -> Settings -> SSH and GPG keys\n",
    "# - Click \"New SSH key\"\n",
    "# - Paste your public key\n",
    "\n",
    "# Then try cloning with:\n",
    "# git clone git@github.com:nodameCL/BondValenceParametersFit.git\n",
    "\n",
    "# If you still get errors, check:\n",
    "# - Your SSH config (~/.ssh/config)\n",
    "# - Network connectivity\n",
    "# - GitHub status (status.github.com)\n",
    "\n",
    "# After cloning and making changes, follow these steps to push code:\n",
    "\n",
    "# 1. Add changed files to staging\n",
    "# git add .\n",
    "\n",
    "# 2. Commit changes with a message\n",
    "# git commit -m \"Your commit message describing changes\"\n",
    "\n",
    "# 3. Push changes to remote repository\n",
    "# git push origin main  # or 'master' depending on your default branch\n",
    "\n",
    "# If you get errors about being behind remote, first pull latest changes:\n",
    "# git pull origin main\n",
    "\n",
    "# Then resolve any merge conflicts and push again:\n",
    "# git push origin main\n",
    "\n",
    "# To create a new branch and push:\n",
    "# git checkout -b new-branch-name\n",
    "# git push -u origin new-branch-name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# download data from materials project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-O containing materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import numpy as np\n",
    "# get matID to possible species dict \n",
    "def get_possible_species_perID(save_dir, docs):\n",
    "    import json \n",
    "    dict_matID_possible_species = {} \n",
    "    for doc in docs: \n",
    "        if doc.possible_species != []: \n",
    "            dict_matID_possible_species[doc.material_id] = doc.possible_species\n",
    "\n",
    "    if not os.path.exists(f'{save_dir}/params'): \n",
    "        os.makedirs(f'{save_dir}/params')\n",
    "        \n",
    "    with open(f'{save_dir}/params/dict_matID_possible_species.json', 'w') as fopen: \n",
    "        json.dump(dict_matID_possible_species, fopen)\n",
    "\n",
    "    return list(dict_matID_possible_species.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = \"YgzOEXsODWlsR0J9P5aSjX2CxHuZX9Zv\"\n",
    "algos = ['shgo', 'brute', 'diff', 'dual_annealing', 'direct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "check_list = np.loadtxt('/Users/chunhuili/SynologyDrive/00Research/00_MINES/00_mp_data_process/no_solu/direct.txt', dtype=str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start calculating Ti-O system:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0e97f063d24b0f93455395f052b1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving SummaryDoc documents:   0%|          | 0/2284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c7371bf29245fba8689dc63d5f6d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving BondingDoc documents:   0%|          | 0/2235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 685/2235 [1:01:49<4:29:04, 10.42s/it] /global/home/users/chli/.local/lib/python3.9/site-packages/scipy/optimize/_optimize.py:404: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n",
      " 55%|█████▌    | 1237/2235 [3:46:27<10:49,  1.54it/s]    spglib: Attempt 0 tolerance = 1.000000e-02 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 1 tolerance = 9.500000e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 2 tolerance = 9.025000e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 3 tolerance = 8.573750e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 4 tolerance = 8.145062e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 5 tolerance = 7.737809e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 6 tolerance = 7.350919e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 7 tolerance = 6.983373e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 8 tolerance = 6.634204e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 9 tolerance = 6.302494e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 10 tolerance = 5.987369e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 11 tolerance = 5.688001e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 12 tolerance = 5.403601e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 13 tolerance = 5.133421e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 0 tolerance = 1.000000e-02 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 1 tolerance = 9.500000e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 2 tolerance = 9.025000e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 3 tolerance = 8.573750e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 4 tolerance = 8.145062e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 5 tolerance = 7.737809e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 6 tolerance = 7.350919e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 7 tolerance = 6.983373e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 8 tolerance = 6.634204e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 9 tolerance = 6.302494e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 10 tolerance = 5.987369e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 11 tolerance = 5.688001e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 12 tolerance = 5.403601e-03 failed(line 800, /project/src/spacegroup.c).\n",
      "spglib: Attempt 13 tolerance = 5.133421e-03 failed(line 800, /project/src/spacegroup.c).\n",
      " 70%|██████▉   | 1559/2235 [6:29:23<18:40:34, 99.46s/it] "
     ]
    }
   ],
   "source": [
    "# bond_valence_processor.py\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from mp_api.client import MPRester\n",
    "from BVparams_search import TheoreticalBondValenceSolver\n",
    "from BVparams_search import BVParamSolver\n",
    "\n",
    "class BondValenceProcessor:\n",
    "    def __init__(self, api_key, algos):\n",
    "        self.api_key = api_key\n",
    "        self.algos = algos\n",
    "        \n",
    "    def process_cation_system(self, cation):\n",
    "        \"\"\"Process a single cation-O system\"\"\"\n",
    "        print(f'start calculating {cation}-O system:')\n",
    "        \n",
    "        # Download dataset\n",
    "        docs = self.download_materials_data(cation)\n",
    "        \n",
    "        # Setup directories and get material IDs\n",
    "        res_dir = f'res/{cation}O'\n",
    "        mids = self.get_possible_species_perID(res_dir, docs)\n",
    "        \n",
    "        # Get bonding data\n",
    "        bonds_docs = self.download_bonding_data(mids)\n",
    "        \n",
    "        # Initialize data structures\n",
    "        dict_sij_perMatID = {}\n",
    "        dict_charges_perMatID = {}\n",
    "        \n",
    "        # Handle previously solved cases\n",
    "        solved_materID, no_solu = self.get_previous_results(res_dir)\n",
    "        \n",
    "        # Initialize solver\n",
    "        sij_solver = TheoreticalBondValenceSolver(\n",
    "            species_matID_path=f'{res_dir}/params/dict_matID_possible_species.json'\n",
    "        )\n",
    "        \n",
    "        # Process each material\n",
    "        self.process_materials(bonds_docs, solved_materID, sij_solver, dict_sij_perMatID, \n",
    "                         dict_charges_perMatID, no_solu, res_dir, cation)\n",
    "        \n",
    "        # Save results\n",
    "        self.save_results(res_dir, dict_sij_perMatID, dict_charges_perMatID)\n",
    "\n",
    "    def download_materials_data(self, cation):\n",
    "        \"\"\"Download materials data from Materials Project\"\"\"\n",
    "        with MPRester(api_key=self.api_key) as mpr:\n",
    "            return mpr.materials.summary.search(\n",
    "                elements=[cation, 'O'],\n",
    "                energy_above_hull=(0.000, 0.05),\n",
    "                fields=['material_id', 'possible_species']\n",
    "            )\n",
    "\n",
    "    def download_bonding_data(self, mids):\n",
    "        \"\"\"Download bonding data from Materials Project\"\"\"\n",
    "        with MPRester(api_key=self.api_key) as mpr:\n",
    "            return mpr.materials.bonds.search(\n",
    "                material_ids=mids,\n",
    "                fields=['material_id', 'structure_graph', 'formula_pretty']\n",
    "            )\n",
    "\n",
    "    def get_previous_results(self, res_dir):\n",
    "        \"\"\"Get previously solved cases\"\"\"\n",
    "        if os.path.exists(f'{res_dir}/R0Bs/shgo'):\n",
    "            solved_sol = os.listdir(f'{res_dir}/R0Bs/shgo/')\n",
    "            solved_materID = [e.split('.txt')[0] for e in solved_sol]\n",
    "            if '.ipynb_checkpoints' in solved_materID:\n",
    "                solved_materID.remove('.ipynb_checkpoints')\n",
    "            \n",
    "            no_solu = np.loadtxt(f'{res_dir}/no_solu/shgo.txt', dtype=str).tolist()\n",
    "            nosol_IDs = [e[0] for e in no_solu]\n",
    "            nosol_IDs = list(set(nosol_IDs))\n",
    "            solved_materID += nosol_IDs\n",
    "        else:\n",
    "            solved_materID = []\n",
    "            no_solu = []\n",
    "        \n",
    "        return solved_materID, no_solu\n",
    "\n",
    "    def process_materials(self, bonds_docs, solved_materID, sij_solver, dict_sij_perMatID,\n",
    "                         dict_charges_perMatID, no_solu, res_dir, cation):\n",
    "        \"\"\"Process each material in the dataset\"\"\"\n",
    "        for Li_mater in tqdm(bonds_docs):\n",
    "            matID = Li_mater.material_id\n",
    "            reduced_formula = Li_mater.formula_pretty\n",
    "            cur_struct = Li_mater.structure_graph.structure\n",
    "            \n",
    "            # Get Sij values\n",
    "            cur_network_valence_dict, cur_bond_type_list, cur_bondL_dict, dict_charge = sij_solver.get_sij(\n",
    "                matID, cur_struct, Li_mater.structure_graph\n",
    "            )\n",
    "            \n",
    "            dict_sij_perMatID[matID] = cur_network_valence_dict\n",
    "            dict_charges_perMatID[matID] = dict_charge\n",
    "\n",
    "            if matID in solved_materID:\n",
    "                continue\n",
    "                \n",
    "            self.process_algorithm_results(cur_network_valence_dict, no_solu, res_dir,\n",
    "                                    cation, matID, reduced_formula, cur_bond_type_list,\n",
    "                                    cur_bondL_dict)\n",
    "\n",
    "    def process_algorithm_results(self, cur_network_valence_dict, no_solu, res_dir,\n",
    "                                cation, matID, reduced_formula, cur_bond_type_list,\n",
    "                                cur_bondL_dict):\n",
    "        \"\"\"Process results using different algorithms\"\"\"\n",
    "        for alg in self.algos:\n",
    "            if not cur_network_valence_dict:\n",
    "                no_solu.append((matID, cation, 'O', reduced_formula, 'no_network_sol'))\n",
    "                np.savetxt(f'{res_dir}/no_solu/{alg}.txt', no_solu, fmt='%s')\n",
    "                continue\n",
    "                \n",
    "            bv_solver = BVParamSolver(save_dir=res_dir, algo=alg, no_sol=no_solu)\n",
    "            \n",
    "            new_R0_B_LiO = bv_solver.solve_R0Bs(\n",
    "                cation=cation,\n",
    "                anion='O',\n",
    "                bond_type_list=cur_bond_type_list,\n",
    "                networkValence_dict=cur_network_valence_dict,\n",
    "                bondLen_dict=cur_bondL_dict,\n",
    "                materID=matID,\n",
    "                chem_formula=reduced_formula,\n",
    "                R0_bounds=(0, 5),\n",
    "            )\n",
    "            \n",
    "            if new_R0_B_LiO:\n",
    "                np.savetxt(f'{res_dir}/R0Bs/{alg}/{matID}.txt', new_R0_B_LiO)\n",
    "\n",
    "    def save_results(self, res_dir, dict_sij_perMatID, dict_charges_perMatID):\n",
    "        \"\"\"Save final results\"\"\"\n",
    "        with open(f'{res_dir}/dict_sijs.json', 'w') as fopen:\n",
    "            json.dump(dict_sij_perMatID, fopen)\n",
    "        \n",
    "        with open(f'{res_dir}/dict_charges.json', 'w') as fopen:\n",
    "            json.dump(dict_charges_perMatID, fopen)\n",
    "\n",
    "# Main processing\n",
    "if __name__ == \"__main__\":\n",
    "    my_api_key = \"YgzOEXsODWlsR0J9P5aSjX2CxHuZX9Zv\"\n",
    "    algos = ['shgo', 'brute', 'diff', 'dual_annealing', 'direct']\n",
    "    processor = BondValenceProcessor(my_api_key, algos)\n",
    "    \n",
    "    for cation in cations:\n",
    "        processor.process_cation_system(cation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
